#!/usr/bin/env python
#import numpy as np
#import cv2
#from cv_bridge import CvBridge, CvBridgeError
import roslib
import rospy
import tf2_ros
import tf2_msgs
import math
import json
import tf2_geometry_msgs
from std_msgs.msg import Int32MultiArray
from geometry_msgs.msg import TransformStamped, Vector3
from geometry_msgs.msg import PoseStamped
from tf.transformations import quaternion_from_euler,euler_from_quaternion


boxes_msg = None
pose_msg = None

def callback_box(msg):
	global boxes_msg
	boxes_msg = msg
	return

def callback_pose(msg):
	global pose_msg
	pose_msg = msg
	return

def publish_sign_id(id):
	sign_pub.publish(id+10)
	
rospy.init_node("sign_tf")
box_sub = rospy.Subscriber('sign_box', Int32MultiArray, callback_box)
pose_sub = rospy.Subscriber('cf1/pose', PoseStamped, callback_pose)
sign_pub = rospy.Publisher('cf1/localization/measurement_feedback', Int32MultiArray, queue_size=1)
br = tf2_ros.TransformBroadcaster()
tf_buf   = tf2_ros.Buffer()
tf_lis = tf2_ros.TransformListener(tf_buf, queue_size=10)



#get all the signs in the map
w_name = rospy.get_param(rospy.get_name() + "/world_name")
with open(w_name, 'rb') as f:
	world = json.load(f)
signs = [s['sign'] for s in world['roadsigns']]


label_file_name = rospy.get_param(rospy.get_name() + '/labels')
rospy.loginfo('reading label file: '+label_file_name)
with open(label_file_name, 'rb') as f:
	labels = f.read().strip().split("\n")
	rospy.loginfo('reading labels:')
	
fy = 220.72391163
fx = 221.88078347
real_size = world['roadsign_size'][0]
H, W = 480,640 #446, 332  #size of undist images


def main():
	global boxes_msg
	rate = rospy.Rate(10) #Hz
	while not rospy.is_shutdown():
		if boxes_msg:
			boxes = boxes_msg
			n = boxes.layout.dim[1].size  #7: [centerX, centerY, id(14 now), height, width, stamp, stamp_ns]
			boxes_msg = None

			#calculate the complete tf of the object(s)

			for i in range(boxes.layout.dim[0].size):
				p = PoseStamped()
				p.header.frame_id = 'cf1/camera_link'

				p.header.stamp.secs = boxes.data[n*i+5]
				p.header.stamp.nsecs = boxes.data[n*i+6]

				#find the depth of found object(s)
				Z = fy*real_size/(boxes.data[n*i+3])
				p.pose.position.z = Z
				p.pose.position.x = (boxes.data[n*i]-W/2)*Z/fx
				p.pose.position.y = (boxes.data[n*i+1]-H/2)*Z/fy
 
				sign_id = boxes.data[n*i+2]
				sign_class = labels[sign_id]
				publish_sign_id(sign_id)
				#rospy.logwarn((boxes.data[n*i+4])*p.pose.position.z/fx)
				#rospy.logwarn(real_size)

				width_world = (boxes.data[n*i+4])*Z/fx
				rospy.logwarn("width : {}".format(width_world))
				if Z < width_world/2 :
					rospy.logwarn("Object to close to get pose, ignoring object")
					continue

				yaw_detected = math.pi - math.asin((width_world/2)/Z) - math.asin(min(real_size, width_world)/real_size)
				#we might want to cancel the rotation of the drone by doing -euler_from_quaternion([pose_msg.pose.orientation.x,
				# 																					pose_msg.pose.orientation.y,
				# 																					pose_msg.pose.orientation.z,
				# 																					pose_msg.pose.orientation.w])[2]
				
				rospy.logwarn('yaw detected : {}'.format(yaw_detected))

				#find orientation:
				if sign_class in signs: #if it exist in the map
					#Transform the map pose of the sign in the same frame
					try:
						trans = tf_buf.lookup_transform("cf1/camera_link", 'sign/' + sign_class, rospy.Time())
					except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):
						rate.sleep()
						continue

					
					yaw_map = euler_from_quaternion([trans.transform.rotation.x,
														trans.transform.rotation.y,
														trans.transform.rotation.z,
														trans.transform.rotation.w])[0] #x axis upwards for the signs

					rospy.logwarn('yaw from map : {}'.format(yaw_map))

					if abs(yaw_map-yaw_detected) > yaw_map+yaw_detected : #get the closest yaw to the real one
						yaw_detected = -yaw_detected

					rospy.logwarn('yaw detected corrected : {}'.format(yaw_detected))

					roll, pitch, yaw = yaw_detected, 0,-3.14/2 #3.14/2, -3.14/2  #weird axis definition..  +90??
					(p.pose.orientation.x,
    				 p.pose.orientation.y,
    				 p.pose.orientation.z,
    				 p.pose.orientation.w) = quaternion_from_euler(roll,
                                                					 pitch,
                                                					 yaw)

				if not tf_buf.can_transform('map', 'cf1/camera_link', rospy.Time(0)):
					rospy.logwarn_throttle(5.0, 'No transform from cf1/camera_link to map')
					return

				p = tf_buf.transform(p, 'map')

				t = TransformStamped()
				t.header.stamp = p.header.stamp
				t.header.frame_id = 'map'
				t.child_frame_id = 'sign_dectected/' + labels[boxes.data[n*i+2]]
				t.transform.translation = p.pose.position
				t.transform.rotation = p.pose.orientation
				br.sendTransform(t)

		rate.sleep()
	return

if __name__ == '__main__':
	main()
